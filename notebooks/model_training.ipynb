{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import pickle\n",
                "import os\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.metrics import accuracy_score\n",
                "\n",
                "# ==========================================\n",
                "# STEP 1: Load & Prepare Data\n",
                "# ==========================================\n",
                "csv_path = \"../dataset/filtered_public_utility_complaints.csv\"\n",
                "\n",
                "print(f\"Loading dataset from: {csv_path}\")\n",
                "try:\n",
                "    df = pd.read_csv(csv_path)\n",
                "    print(f\"Dataset loaded successfully. Shape: {df.shape}\")\n",
                "except FileNotFoundError:\n",
                "    print(f\"Error: File not found at {csv_path}\")\n",
                "    # Stop execution if file not found (in a notebook, we can just raise or exit)\n",
                "    raise\n",
                "\n",
                "# Define Input and Output\n",
                "if 'Consumer complaint narrative' not in df.columns or 'category' not in df.columns:\n",
                "    raise ValueError(\"Dataset missing required columns: 'Consumer complaint narrative' or 'category'\")\n",
                "\n",
                "X = df['Consumer complaint narrative'].astype(str) # Ensure all are strings\n",
                "y = df['category']\n",
                "\n",
                "print(f\"Input samples: {len(X)}\")\n",
                "print(f\"Target distribution:\\n{y.value_counts()}\")\n",
                "\n",
                "# ==========================================\n",
                "# STEP 2: Feature Extraction\n",
                "# ==========================================\n",
                "print(\"\\nPerforming TF-IDF Vectorization...\")\n",
                "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
                "X_vectorized = vectorizer.fit_transform(X)\n",
                "print(f\"Vectorization complete. Shape: {X_vectorized.shape}\")\n",
                "\n",
                "# ==========================================\n",
                "# STEP 3: Model Training\n",
                "# ==========================================\n",
                "print(\"\\nSplitting data into Train/Test (80/20)...\")\n",
                "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)\n",
                "\n",
                "print(\"Training Logistic Regression model...\")\n",
                "model = LogisticRegression(max_iter=1000)\n",
                "model.fit(X_train, y_train)\n",
                "print(\"Training complete.\")\n",
                "\n",
                "# ==========================================\n",
                "# STEP 4: Model Evaluation\n",
                "# ==========================================\n",
                "print(\"\\nEvaluating model...\")\n",
                "y_pred = model.predict(X_test)\n",
                "accuracy = accuracy_score(y_test, y_pred)\n",
                "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
                "\n",
                "# ==========================================\n",
                "# STEP 5: Save Model Files\n",
                "# ==========================================\n",
                "# Ensure the target directory exists\n",
                "model_dir = \"../backend/app/models\"\n",
                "os.makedirs(model_dir, exist_ok=True)\n",
                "\n",
                "model_path = os.path.join(model_dir, \"model.pkl\")\n",
                "vectorizer_path = os.path.join(model_dir, \"vectorizer.pkl\")\n",
                "\n",
                "print(f\"\\nSaving model to: {model_path}\")\n",
                "with open(model_path, \"wb\") as f:\n",
                "    pickle.dump(model, f)\n",
                "\n",
                "print(f\"Saving vectorizer to: {vectorizer_path}\")\n",
                "with open(vectorizer_path, \"wb\") as f:\n",
                "    pickle.dump(vectorizer, f)\n",
                "\n",
                "print(\"\\nAll tasks completed successfully.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}